{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLOHWXT7RsgIfMU3uLf5eD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MIE524 - Lab 1 - Spark Warm-up\n"],"metadata":{"id":"UD7L2bNG6v_9"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"J6OCqCkT64Qz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxb5YQ4q2wOh"},"outputs":[],"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""]},{"cell_type":"code","source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"metadata":{"id":"orvjXAZO7GXq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Word Count with Spark\n","We will work with the *pg100.txt* file which contains a copy of the complete works of Shakespeare."],"metadata":{"id":"_axemJ8Sibkm"}},{"cell_type":"code","source":["id='1FV9oO0opIaww85HGR0Oe_mv6FSOmzVZ6'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('pg100.txt')"],"metadata":{"id":"152TYTX9hqZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's import the libraries we will need\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import pyspark\n","from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf"],"metadata":{"id":"lfbfhFSMM8g0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"],"metadata":{"id":"ACVJZFoHhqcY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"id":"PSQrqdwON8QP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the dataset:"],"metadata":{"id":"Zwi_pW_Cok7S"}},{"cell_type":"code","source":["# txt = spark.read.text(\"pg100.txt\")\n","rdd = spark.sparkContext.textFile(\"pg100.txt\")"],"metadata":{"id":"GKFXQ2_DmrI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd.take(10)"],"metadata":{"id":"dh0g7vtZpmeI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Remove punctuation and transform all words to lower case using **map ()**"],"metadata":{"id":"2eTq-dmNnatW"}},{"cell_type":"code","source":["def lower_str(x):\n","  lowercase_str = x.lower()\n","  return lowercase_str\n","\n","rdd = rdd.map(lower_str)\n","\n","def strip_punc(x):\n","  punc = '!\"#$%&\\'()*+,.:;<=>?@[\\\\]^_`{|}-~'\n","  for c in punc:\n","    x_clean = x.replace(c, '')\n","  return x_clean\n","\n","rdd = rdd.map(strip_punc)"],"metadata":{"id":"6ExS6EF0mrXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd.take(10)"],"metadata":{"id":"VbWLsoNymrau"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Split sentences in words using **flatMap()**"],"metadata":{"id":"-aiYSdFarPk0"}},{"cell_type":"code","source":["rdd = rdd.flatMap(lambda line: line.split(\" \"))\n","rdd.take(10)"],"metadata":{"id":"h_CjBZ6zrcJy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exclude whitespaces using **filter()**"],"metadata":{"id":"nGDAfn4tryf-"}},{"cell_type":"code","source":["rdd = rdd.filter(lambda x:x!='')\n","rdd.take(10)"],"metadata":{"id":"mSzCT6fArcX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Count how many times each word occurs using **reduceByKey()**"],"metadata":{"id":"nmIWgDlzsJMP"}},{"cell_type":"code","source":["# initialize (key,val) pair RDD\n","rdd_count = rdd.map(lambda word:(word,1))\n","rdd_count.take(10)"],"metadata":{"id":"2-jrcE1vrcay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd_count_rbk = rdd_count.reduceByKey(lambda x,y:(x+y)).sortByKey()\n","rdd_count_rbk.take(10)"],"metadata":{"id":"UTuDGAdCsm-v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rank by frequency of occurence"],"metadata":{"id":"iJCmJDnYtAHy"}},{"cell_type":"code","source":["# switch (key,val) pairs as (val,key)\n","rdd_count_rbk = rdd_count_rbk.map(lambda x:(x[1],x[0]))\n","rdd_count_rbk.take(10)"],"metadata":{"id":"msjcUgOjs_ty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd_count_rbk.sortByKey(False).take(10)"],"metadata":{"id":"fu8gOAJHsnB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd_count_rbk.saveAsTextFile('counts')"],"metadata":{"id":"KxIFofUUAXBD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Oxford Covid-19 Government Response Tracker\n","\n","We will analyze the Oxford Covid-19 Government Response Tracker data available [here](https://github.com/OxCGRT/covid-policy-tracker/tree/master).\n","\n","\n","The Oxford Covid-19 Government Response Tracker (OxCGRT) collects systematic information on policy measures that governments have taken to tackle COVID-19.\n","\n","The different policy responses are tracked since 1 January 2020, cover more than 180 countries and are coded into 23 indicators, such as school closures, travel restrictions, vaccination policy. These policies are recorded on a scale to reflect the extent of government action, and scores are aggregated into a suite of policy indices. The data can help decision-makers and citizens understand governmental responses in a consistent way, aiding efforts to fight the pandemic.\n","\n","https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker\n","\n","\n","**OxCGRT** [Get the dataset here](https://drive.google.com/file/d/1ECXsyH6HtWjTa8VpHweFQs1ceq29niFo/view?usp=share_link)\n"],"metadata":{"id":"S4iHAturhrDR"}},{"cell_type":"code","source":["id='1ECXsyH6HtWjTa8VpHweFQs1ceq29niFo'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('OxCGRT_nat_latest.csv')"],"metadata":{"id":"2ms8FBNJ7ojI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"],"metadata":{"id":"iXEd-nlFNWsE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the dataset:"],"metadata":{"id":"lutmcnIlQfgg"}},{"cell_type":"code","source":["OxCGRT_latest = spark.read.option(\"header\", True).csv(\"OxCGRT_nat_latest.csv\")\n"],"metadata":{"id":"H5kEtQINOD6R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check the schema:"],"metadata":{"id":"4MFU_U74QvWt"}},{"cell_type":"code","source":["OxCGRT_latest.printSchema()"],"metadata":{"id":"4aJpSiVRQrUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get a sample with take():"],"metadata":{"id":"qwh6tcvIQ7En"}},{"cell_type":"code","source":["OxCGRT_latest.take(3)"],"metadata":{"id":"RbDOwMp5Qyyy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get a formatted sample with `show()`:"],"metadata":{"id":"DWXmKiT2TLRh"}},{"cell_type":"code","source":["OxCGRT_latest.show()"],"metadata":{"id":"SzzTuEyuQ-2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"In total there are {0} records\".format(OxCGRT_latest.count()))"],"metadata":{"id":"U2ZJHi9lTM3a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can check the levels on each policy [here](https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md)."],"metadata":{"id":"oHgBFMXqkwMJ"}},{"cell_type":"markdown","source":["## Q1: Which are the top 20 countries that had their schools closed for the longest period of time?\n","C1M_School closing = 3"],"metadata":{"id":"_nf3k1J3k3aK"}},{"cell_type":"code","source":["school_closing_counts = OxCGRT_latest.where(\"`C1M_School closing` = 3\")\\\n","                                    .groupBy(\"CountryName\")\\\n","                                    .agg(count(\"*\").alias(\"C1M_School_closing_count\"))\\\n","                                    .sort(desc(\"C1M_School_closing_count\"))\n","school_closing_counts.show()"],"metadata":{"id":"NmC0r4H3TYtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OxCGRT_latest.createOrReplaceTempView(\"OxCGRT_latest\")\n","\n","query = \"\"\"\n","SELECT CountryName, count(*) as C1M_School_closing_count\n","FROM OxCGRT_latest\n","WHERE `C1M_School closing` = 3\n","GROUP BY CountryName\n","ORDER BY C1M_School_closing_count DESC\n","\"\"\"\n","\n","school_closing_counts = spark.sql(query)\n","school_closing_counts.show()"],"metadata":{"id":"ou48cV5blw3n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Move to Pandas"],"metadata":{"id":"ugRHjS7T2GmZ"}},{"cell_type":"code","source":["school_closing_counts_pd = school_closing_counts.toPandas()\n","school_closing_counts_pd.head()"],"metadata":{"id":"GH1kzhD_1TCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pl = school_closing_counts_pd.head(20).plot(kind=\"bar\",\n","                            x=\"CountryName\", y=\"C1M_School_closing_count\",\n","                            figsize=(10, 7), alpha=0.5, color=\"olive\")\n","pl.set_xlabel(\"Country\")\n","pl.set_ylabel(\"Number of Days Schools Closed\")\n"],"metadata":{"id":"1Alz3PSY2L10"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q2: What are the total number of confirmed cases?\n","Find these values for CountryName IN [Canada, United States, India, United Kingdom, China, Iran, Brazil, Australia, and South Africa].\n","\n","\n"],"metadata":{"id":"eAWrMapN3UVg"}},{"cell_type":"markdown","source":["First, get a lits of country names."],"metadata":{"id":"gQHswGCQ4O0z"}},{"cell_type":"code","source":["confirmed_cases_countries = OxCGRT_latest.selectExpr([\"CountryName\", \"to_date(Date,'yyyyMMdd') as Date\", \"ConfirmedCases\", \"GovernmentResponseIndex_Average\"])\\\n","                                        .where(\"CountryName IN ('Canada', 'United States', 'India', 'United Kingdom', 'China', 'Iran', 'Brazil', 'Australia', 'South Africa')\")\n","confirmed_cases_countries.show()"],"metadata":{"id":"hP6oog-O6BSA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confirmed_cases_daily = confirmed_cases_countries.where(\"CountryName IN ('Canada', 'United States', 'India', 'United Kingdom', 'China', 'Iran', 'Brazil', 'Australia', 'South Africa')\")\\\n","                                    .toPandas()\n","confirmed_cases_daily.head()"],"metadata":{"id":"Etzh7vcM-mdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(10, 6))\n","\n","# iterate the different groups to create a different series\n","for country, confimed_case in confirmed_cases_daily.groupby(\"CountryName\"):\n","    plt.plot(confimed_case[\"Date\"], confimed_case[\"ConfirmedCases\"].fillna(0), label=country)\n","\n","\n","plt.legend(loc='best')"],"metadata":{"id":"lyyvxopE-fjj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q3: What are the daily confirmed cases?\n","The *ConfirmedCases* columns is a cumulative sum, we need to convert them to daily values first.\n","\n","Find these values for CountryName IN [Canada, United States, India, United Kingdom, China, Iran, Brazil, Australia, and South Africa]."],"metadata":{"id":"0Ikb1ysTCTGR"}},{"cell_type":"code","source":["from pyspark.sql.window import Window\n","import pyspark.sql.functions as f\n","\n","window = Window.partitionBy(\"CountryName\").orderBy(\"Date\")\n","\n","daily_confirmed_cases = confirmed_cases_countries.withColumn(\"ConfirmedCases\", f.col(\"ConfirmedCases\") - f.lag(f.col(\"ConfirmedCases\"), 1, 0).over(window))\n","\n","daily_confirmed_cases.show()"],"metadata":{"id":"Sh6qb4ZT6AKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["daily_confirmed_cases_df = daily_confirmed_cases.toPandas()\n","\n","fig = plt.figure(figsize=(10, 6))\n","\n","# iterate the different groups to create a different series\n","for country, confimed_case in daily_confirmed_cases_df.groupby(\"CountryName\"):\n","    plt.plot(confimed_case[\"Date\"], confimed_case[\"ConfirmedCases\"].fillna(0), label=country)\n","\n","\n","plt.legend(loc='best')"],"metadata":{"id":"8yyX6pwc571X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q4: Plot the Government Response Index vs the daily number of confirmed cases.\n","\n","Create a plot for each of the following countries [Canada, United States, India, United Kingdom, China, Iran, Brazil, Australia, and South Africa].\n","\n","\n"],"metadata":{"id":"9aJJbKIpE58D"}},{"cell_type":"code","source":["for country, confimed_case in daily_confirmed_cases_df.groupby(\"CountryName\"):\n","    fig, ax1 = plt.subplots()\n","    ax2 = ax1.twinx()\n","    ax1.plot(confimed_case[\"Date\"], confimed_case[\"ConfirmedCases\"].fillna(0), 'g-')\n","    ax2.plot(confimed_case[\"Date\"], confimed_case[\"GovernmentResponseIndex_Average\"].fillna(0), 'b-')\n","    plt.title(country)\n","    plt.show()"],"metadata":{"id":"RCrJuYGEEafc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8U0yCgEbF--T"},"execution_count":null,"outputs":[]}]}